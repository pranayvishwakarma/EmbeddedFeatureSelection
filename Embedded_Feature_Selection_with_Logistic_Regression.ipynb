{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "05fb64de",
      "metadata": {
        "id": "05fb64de"
      },
      "source": [
        "# Embedded Feature Selection for DDoS Attack Detection\n",
        "\n",
        "This notebook preprocesses the dataset and applies different embedded feature selection techniques to determine the most effective method.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqvFxhUzGl47",
        "outputId": "94e8c23d-671e-4285-9f16-b6161e5e1679"
      },
      "id": "AqvFxhUzGl47",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "23ccad56",
      "metadata": {
        "id": "23ccad56"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Syn.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLAsfLCsHz6w",
        "outputId": "aeea38c2-4def-4bff-df01-0714dfa27321"
      },
      "id": "YLAsfLCsHz6w",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b02c97c0306a>:2: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/MyDrive/Syn.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3bb1dc93",
      "metadata": {
        "id": "3bb1dc93"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns\n",
        "df.drop(df.columns[[1,2,3,4,5,7,85]], axis=1, inplace=True)\n",
        "\n",
        "# Encode target variable\n",
        "df['Label_new'] = df[' Label'].apply(lambda x: 1 if x == 'Syn' else 0 if x == 'BENIGN' else None)\n",
        "df.drop(columns=[' Label'], inplace=True, errors='ignore')\n",
        "\n",
        "# Remove NaN and infinite values\n",
        "df = df.dropna()\n",
        "df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "# **Dataset Balancing BEFORE Splitting**\n",
        "df_benign = df[df['Label_new'] == 0]\n",
        "df_attack = df[df['Label_new'] == 1]\n",
        "\n",
        "# Upsample benign traffic (1/3 of attack samples)\n",
        "df_benign_upsampled = resample(df_benign,\n",
        "                               replace=True,\n",
        "                               n_samples=len(df_attack) // 3,\n",
        "                               random_state=42)\n",
        "\n",
        "# Downsample attack traffic (50% reduction)\n",
        "df_attack_downsampled = resample(df_attack,\n",
        "                                 replace=False,\n",
        "                                 n_samples=len(df_attack) // 2,\n",
        "                                 random_state=42)\n",
        "\n",
        "# Merge balanced dataset\n",
        "df_balanced = pd.concat([df_benign_upsampled, df_attack_downsampled])\n",
        "\n",
        "# Shuffle dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split into features & target\n",
        "X = df_balanced.drop(columns=['Label_new'])\n",
        "y = df_balanced['Label_new']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "label_counts = Counter(y)  # Count occurrences of each label\n",
        "print(\"Label counts before splitting:\", label_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5FJQdTwTPqk",
        "outputId": "3b977c0d-d154-497c-93ad-2a5511b34635"
      },
      "id": "Q5FJQdTwTPqk",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label counts before splitting: Counter({1: 689991, 0: 459994})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "AIFrJshpTNGv"
      },
      "id": "AIFrJshpTNGv",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "9vGJMkjwHYEx"
      },
      "id": "9vGJMkjwHYEx",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2a24c66d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a24c66d",
        "outputId": "d2a1e58e-e816-49ef-a8d4-452a9708dcae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LASSO Feature Selection Accuracy (Logistic Regression): 0.9972912690165524\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     91999\n",
            "           1       1.00      1.00      1.00    137998\n",
            "\n",
            "    accuracy                           1.00    229997\n",
            "   macro avg       1.00      1.00      1.00    229997\n",
            "weighted avg       1.00      1.00      1.00    229997\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# **1️⃣ LASSO Feature Selection**\n",
        "from sklearn.linear_model import Lasso, LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Fit LASSO for feature selection\n",
        "lasso = Lasso(alpha=0.01)\n",
        "lasso.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Select only non-zero coefficient features\n",
        "lasso_selected_features = X.columns[lasso.coef_ != 0]\n",
        "X_train_lasso = X_train[lasso_selected_features]\n",
        "X_test_lasso = X_test[lasso_selected_features]\n",
        "\n",
        "# Train Logistic Regression on LASSO-selected features\n",
        "lasso_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "lasso_model.fit(X_train_lasso, y_train)\n",
        "y_pred_lr = lasso_model.predict(X_test_lasso)\n",
        "\n",
        "# Accuracy & Classification Report\n",
        "print(\"LASSO Feature Selection Accuracy (Logistic Regression):\", accuracy_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "806c2ddd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "806c2ddd",
        "outputId": "99a37dca-948e-4ef7-974d-85a046a6e7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Feature Selection Accuracy (Logistic Regression): 0.9333165215198459\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.83      0.91     91999\n",
            "           1       0.90      1.00      0.95    137998\n",
            "\n",
            "    accuracy                           0.93    229997\n",
            "   macro avg       0.95      0.92      0.93    229997\n",
            "weighted avg       0.94      0.93      0.93    229997\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# **2️⃣ Ridge Feature Selection**\n",
        "from sklearn.linear_model import Ridge, LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Fit Ridge for feature selection\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Select features with absolute coefficient above threshold\n",
        "ridge_selected_features = X.columns[np.abs(ridge.coef_) > 0.01]\n",
        "X_train_ridge = X_train[ridge_selected_features]\n",
        "X_test_ridge = X_test[ridge_selected_features]\n",
        "\n",
        "# Train Logistic Regression on Ridge-selected features\n",
        "ridge_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "ridge_model.fit(X_train_ridge, y_train)\n",
        "y_pred_ridge = ridge_model.predict(X_test_ridge)\n",
        "\n",
        "# Accuracy & Classification Report\n",
        "print(\"Ridge Feature Selection Accuracy (Logistic Regression):\", accuracy_score(y_test, y_pred_ridge))\n",
        "print(classification_report(y_test, y_pred_ridge))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4bd3e4a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bd3e4a9",
        "outputId": "67e9ffb3-c805-489b-92d6-b705d01e4a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Feature Selection Accuracy (Logistic Regression): 0.9996086905481376\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     91999\n",
            "           1       1.00      1.00      1.00    137998\n",
            "\n",
            "    accuracy                           1.00    229997\n",
            "   macro avg       1.00      1.00      1.00    229997\n",
            "weighted avg       1.00      1.00      1.00    229997\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# **3️⃣ Decision Tree Feature Selection**\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train Decision Tree for feature importance\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Select features with importance > 0.01\n",
        "tree_selected_features = X.columns[tree.feature_importances_ > 0.01]\n",
        "X_train_tree = X_train[tree_selected_features]\n",
        "X_test_tree = X_test[tree_selected_features]\n",
        "\n",
        "# Train Logistic Regression on selected features\n",
        "tree_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "tree_model.fit(X_train_tree, y_train)\n",
        "y_pred_tree = tree_model.predict(X_test_tree)\n",
        "\n",
        "# Accuracy & Classification Report\n",
        "print(\"Decision Tree Feature Selection Accuracy (Logistic Regression):\", accuracy_score(y_test, y_pred_tree))\n",
        "print(classification_report(y_test, y_pred_tree))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b5574de6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5574de6",
        "outputId": "9ab5b8c4-29cf-473c-fe9a-c4146dd057cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:19:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Feature Selection Accuracy (Logistic Regression): 0.9996086905481376\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     91999\n",
            "           1       1.00      1.00      1.00    137998\n",
            "\n",
            "    accuracy                           1.00    229997\n",
            "   macro avg       1.00      1.00      1.00    229997\n",
            "weighted avg       1.00      1.00      1.00    229997\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# **4️⃣ XGBoost Feature Selection**\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train XGBoost for feature importance\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Select features with importance > 0.01\n",
        "xgb_selected_features = X.columns[xgb.feature_importances_ > 0.01]\n",
        "X_train_xgb = X_train[xgb_selected_features]\n",
        "X_test_xgb = X_test[xgb_selected_features]\n",
        "\n",
        "# Train Logistic Regression on selected features\n",
        "xgb_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "xgb_model.fit(X_train_xgb, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test_xgb)\n",
        "\n",
        "# Accuracy & Classification Report\n",
        "print(\"XGBoost Feature Selection Accuracy (Logistic Regression):\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(classification_report(y_test, y_pred_xgb))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qd66pk74EoGM"
      },
      "id": "Qd66pk74EoGM",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}